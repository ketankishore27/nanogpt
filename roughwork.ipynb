{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f81636-2b27-4c0b-91be-ec8f59821756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from config.config import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from lightning_wrapper.data_module_wrapper import data_lightning_wrapper\n",
    "from lightning_wrapper.gpt_model_wrapper import lightning_GPTModel_wrapper\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db24469-496c-40ab-8655-bf2bba14f6b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data_lightning_wrapper(path = \"openwebtext\", batch_size = batch_size)\n",
    "data.setup(stage='fit', make_files=False) # <-------------------------------------Check this before running\n",
    "train_dataloader = data.train_dataloader()\n",
    "val_dataloader = data.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f70a7fb-c2d4-47b3-9622-a703246360f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fd30385-015b-410c-afaf-a294878f9b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = np.memmap(\"./data/train.bin\", dtype = np.uint16, mode = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a7ceb8d-53f4-4dbd-8dd0-47c9dd1f3c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff75aff-8498-4746-a2a6-2269cda244c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9031110616"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa21e5df-5d0c-430f-90ad-96f86b48f7e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_splits_new(df_to_split):\n",
    "    ix = torch.randint(len(df_to_split) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy(df_to_split[i:i+block_size].astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy(df_to_split[i+1:i+1+block_size].astype(np.int64)) for i in ix])\n",
    "    if device:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f3849a1-eb67-4fbf-a539-18739b204401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ix = torch.randint(len(train_data) - block_size, (batch_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d808baaf-927c-428e-995b-57ad86fb752e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1129616797, 8502266981, 5214582191, 4564008612, 6480675035, 8855510111,\n",
       "        6017904542, 4950190383, 2170432876, 1378821104, 2644402414, 4432659712])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b33bd-6fa7-4fad-952b-955c9eef9c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be9d3d-e356-476c-a76e-9fdbadaf4b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8775de4-77aa-4f27-b616-c6f3329d422a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0866a-2769-440f-bd8c-8f41121743c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9086d6-4049-4dc3-8552-ee2098f4d7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45533-f964-49af-a64b-0eb224533664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3712e5-7dbf-45ec-aea6-48ae4fb977fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff2109-09c3-45ac-bbeb-0e4222e423d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e72dab-910b-4fe6-b0df-bd45b9b9361e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10cc19-dc59-47e6-b420-dd43966ce901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3d2b0-7d92-4868-b634-3d06c449c571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c80f86-8069-4f62-b759-d8518697d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e086b-00e8-4ac1-a7a3-b06f4118b12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8445b9e-3744-4bed-921c-7fc06e77ab68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd7daf-b11d-49a9-a07f-1bd7aa7d345b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39941031-6f78-4e5d-bff7-99b531a35003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d1eb0-43b3-42da-8be8-2e21570afdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de376c8-b069-49b2-b192-3d4b4435ca83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694a731-e89c-47ff-979d-6478ebbdab82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f960ff-68d3-4320-9387-c63755273b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79656f81-2d49-40e1-a4f0-814f6beaa97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6fa694-3356-4f46-8bca-5b6ef03f725f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139abe5-7d43-4120-8eee-ed75d02311c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1adc3514-e951-44da-85ab-85c76e6adde2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eca45ee-dcc3-4f18-b3f6-b775c693c43e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from config.config import *\n",
    "from data.prepare import charEncoder\n",
    "from model.model import AttentionHead, MultiHeadAttention, SimpleFeedForward, TransformerBlock\n",
    "from model.utilities import evaluate_loss\n",
    "import torch\n",
    "import tiktoken\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from lightning_wrapper.data_module_wrapper import data_lightning_wrapper\n",
    "from lightning_wrapper.gpt_model_wrapper import lightning_GPTModel_wrapper\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "wandb_logger = WandbLogger()\n",
    "\n",
    "torch.manual_seed(13379)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf19be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ab3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c5c1f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[220]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d817e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[220]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([encoder.encode_ordinary(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "780086a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b279a7-a187-4a24-ad4d-d57253b50b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750a4f76-b45e-40d4-bc8c-1e60be629076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data_lightning_wrapper(path = \"openwebtext\", batch_size = 32)\n",
    "data.setup(stage='fit', make_files=False)\n",
    "train_dataloader = data.train_dataloader()\n",
    "val_dataloader = data.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ae5247-3166-4068-9a13-6dfad3b4764e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it = iter(train_dataloader)\n",
    "# x = next(it)\n",
    "# print(data.encoder.decode(x[0][2].tolist()))\n",
    "# print(data.encoder.decode(x[1][2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0354307c-1291-4d7f-82af-cbef0ec275e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "it = iter(train_dataloader)\n",
    "x = next(it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037480aa-ad33-41c6-9bcc-f6b58cbff273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feb2a0bb-1257-4d6c-8675-1e6c59df19b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run lightning_wrapper/gpt_model_wrapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4b667-29bf-4114-9c1e-8a180bddb86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec40e7db-756d-4cea-b7b7-e75b1c34351c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath = \"./checkpoint/\", monitor = \"val_loss\", save_top_k=2, every_n_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7717fd-bfb3-41c7-aa96-9ed61c8854ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = 10, check_val_every_n_epoch=5, accelerator=\"mps\", logger = wandb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e1a7139-c19e-45b2-b976-e7cf1498814d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = lightning_GPTModel_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d717c58b-cbc4-4606-954d-4e64ed69b27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mps_device = torch.device(\"mps\")\n",
    "#model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a8d3b3e-d9f0-4516-a354-fa3c53ae8e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                | Type       | Params\n",
      "---------------------------------------------------\n",
      "0 | token_embeddings    | Embedding  | 38.6 M\n",
      "1 | position_embeddings | Embedding  | 196 K \n",
      "2 | lm_head             | Linear     | 38.6 M\n",
      "3 | block               | Sequential | 85.0 M\n",
      "4 | layer_norm3         | LayerNorm  | 1.5 K \n",
      "---------------------------------------------------\n",
      "162 M     Trainable params\n",
      "0         Non-trainable params\n",
      "162 M     Total params\n",
      "649.880   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a7c0a58c85423cad316707b195c6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "_share_filename_: only available on CPU",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 520\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    550\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    555\u001b[0m     ckpt_path,\n\u001b[1;32m    556\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    940\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:976\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 976\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1005\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1002\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1005\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1007\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:98\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@_no_grad_context\u001b[39m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_OUT_DICT]:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:168\u001b[0m, in \u001b[0;36m_EvaluationLoop.setup_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_batches \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dl \u001b[38;5;129;01min\u001b[39;00m combined_loader\u001b[38;5;241m.\u001b[39mflattened:\n\u001b[0;32m--> 168\u001b[0m     \u001b[43m_check_dataloader_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     dl \u001b[38;5;241m=\u001b[39m _process_dataloader(trainer, dl)\n\u001b[1;32m    170\u001b[0m     dataloaders\u001b[38;5;241m.\u001b[39mappend(dl)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:383\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[0;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_dataloader_iterable\u001b[39m(\n\u001b[1;32m    378\u001b[0m     dataloader: \u001b[38;5;28mobject\u001b[39m,\n\u001b[1;32m    379\u001b[0m     source: _DataLoaderSource,\n\u001b[1;32m    380\u001b[0m     trainer_fn: TrainerFn,\n\u001b[1;32m    381\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m         \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;66;03m# A prefix in the message to disambiguate between the train- and (optional) val dataloader that .fit() accepts\u001b[39;00m\n\u001b[1;32m    386\u001b[0m         prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer_fn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1036\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env_new/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:358\u001b[0m, in \u001b[0;36mreduce_storage\u001b[0;34m(storage)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pickle CUDA storage; try pickling a CUDA tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m get_sharing_strategy() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_system\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 358\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_share_filename_cpu_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    360\u001b[0m     rebuild \u001b[38;5;241m=\u001b[39m rebuild_storage_filename\n",
      "\u001b[0;31mRuntimeError\u001b[0m: _share_filename_: only available on CPU"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8091e6f8-80d4-4638-82b0-e281d54e55e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1dca76a1-cb22-4b5b-b484-a916cba960e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46ffb97c-29e7-418b-ad8d-897d364ee220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "it = iter(data.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41a56ed7-4876-4eae-a337-55b588b64676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70e6d868-2b9c-455a-ad98-404949eea6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" royalties and rights of banish'd Hereford?\\nIs not Gaunt dead, and doth not Hereford live?\\nWas not Gaunt just, and is not Harry true?\\nDid not the one deserve to have an heir?\\nIs not his heir a well-deserving son?\\nTake Hereford's rights away, and take from \""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.encoder.decode(x.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cecd0aa-d9f3-4f1c-9e35-ff2717a13ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1, 56, 53,  ..., 53, 51,  1],\n",
       "         [10,  1, 39,  ..., 46, 43,  1],\n",
       "         [50,  1, 58,  ..., 42,  1, 51],\n",
       "         ...,\n",
       "         [ 1, 51, 39,  ..., 52, 42, 57],\n",
       "         [ 1, 37, 53,  ..., 46, 43, 51],\n",
       "         [40, 53, 52,  ..., 46, 57, 53]], device='mps:0'),\n",
       " tensor([[56, 53, 63,  ..., 51,  1, 32],\n",
       "         [ 1, 39,  1,  ..., 43,  1, 52],\n",
       "         [ 1, 58, 43,  ...,  1, 51, 39],\n",
       "         ...,\n",
       "         [51, 39, 52,  ..., 42, 57, 46],\n",
       "         [37, 53, 56,  ..., 43, 51,  1],\n",
       "         [53, 52, 43,  ..., 57, 53, 51]], device='mps:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9fb6ba5-a5f2-481d-806b-eeb4046323e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, t\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.encoder.decode(next(it).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6decbb-3d71-45da-9173-14721a3e9659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39d3dc1b-07a9-44f3-be82-be9a22cc304e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_train, encoder_test, encoder = create_data_encodings(path=\"./data/text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e7183b7-3758-47b1-b7a2-ccd5d12a1f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5962, 22307,    25, ...,   508,  2058,   607])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "979cf1a9-ebc2-4e60-9d48-b86dcad4de6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.decode(encoder_train[:5].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3313817-9fb8-46b9-9493-f61e6a774490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_train_data, encoded_test_data, encoder = create_data_encodings(path=\"./data/text.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "740bdc7c-ce41-4bcd-b745-efaa0f6a4483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'n_vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_vocab\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'n_vocab'"
     ]
    }
   ],
   "source": [
    "print(encoder.n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a24ff0-e2da-46eb-bc4d-d05fe8503c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_train_data, encoded_test_data, encoder = get_charEncoding(path=\"./data/text.txt\")\n",
    "data_x, data_y = create_splits(encoded_train_data, encoded_test_data, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5c1b4a-38c9-40bd-b6a6-8f3a517d02a6",
   "metadata": {
    "gather": {
     "logged": 1680954061207
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_train_data.tofile(\"./data/train.bin\")\n",
    "encoded_test_data.tofile(\"./data/test.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d11a51b-5573-4241-9d32-de5e849f28bf",
   "metadata": {
    "gather": {
     "logged": 1680954061565
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.n_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d471a646-7075-4143-968b-1ff6beb1bab4",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aea0b2f-e69b-4592-8cc2-e35ecd24d229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, time, single_embed_size = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        wei = q @ k.transpose(-2, -1) * single_embed_size**-0.5\n",
    "        masked_output = wei.masked_fill(self.tril[:time, :time] == 0, float('-inf'))\n",
    "        masked_softmax = F.softmax(masked_output, dim=1)\n",
    "        output = masked_softmax @ v\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ab1195-cc8d-4f3f-b2c3-4ab3d72c52fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embeddings = nn.Embedding(block_size, n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "        self.att_head = AttentionHead()\n",
    "        self.apply(self.__init_weights__)\n",
    "        \n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weights'):\n",
    "                torch.nn.init.normal_(p, mean = 0.0, std = 0.02 / math.sqrt(2 * n_layer))\n",
    "        \n",
    "        \n",
    "    def __init_weights__(self, module):    \n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "                \n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean = 0.0, std = 0.02)\n",
    "            \n",
    "            \n",
    "    def forward(self, idx, target = None):\n",
    "\n",
    "        B, T = idx.shape\n",
    "        token_embeddings = self.token_embeddings(idx)\n",
    "        positional_embeddings = self.position_embeddings(torch.arange(T, device=device))\n",
    "        x = token_embeddings + positional_embeddings\n",
    "        x = self.att_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if target is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch, block, channel = logits.shape\n",
    "            logits = logits.view(batch * block, channel)\n",
    "            target = target.view(batch * block)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate_captions(self, idx, max_tokens):\n",
    "        for _ in range(max_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim = 1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat([idx, idx_next], dim = 1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc25018-6838-42d1-82fd-490d30c8b0a6",
   "metadata": {
    "gather": {
     "logged": 1680954084134
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPTModel()\n",
    "if compile:\n",
    "    model = torch.compile(model).to(device)\n",
    "else:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fdb65d7-ac85-4e67-9af3-decd0a5e7582",
   "metadata": {
    "gather": {
     "logged": 1680954084300
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(65, 32)\n",
       "  (position_embeddings): Embedding(8, 32)\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       "  (att_head): AttentionHead(\n",
       "    (key): Linear(in_features=32, out_features=16, bias=False)\n",
       "    (query): Linear(in_features=32, out_features=16, bias=False)\n",
       "    (value): Linear(in_features=32, out_features=16, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eca44f63-2c77-4f0f-abe4-248d2c9dd4f1",
   "metadata": {
    "gather": {
     "logged": 1680954084430
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 8]), torch.Size([32, 8]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17c12c-0853-4855-aeb7-473e5736baff",
   "metadata": {
    "gather": {
     "logged": 1680954094802
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60b54f96-ff32-4e76-af99-527110cc4c4e",
   "metadata": {
    "gather": {
     "logged": 1680954100077
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ur.FTV$KKQtlNQR;$RDqguEUjLukj3SgQr!f'u.lLp!j'Jn BpF&gQ3yFvEQf,m!nPoggMnF&ofB\n",
      "'?qLTc&BdvDyle$'Qsuqiis\n"
     ]
    }
   ],
   "source": [
    "print(encoder.decode(model.generate_captions(torch.zeros((1, 1), dtype = torch.long).to(device), 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fd7e9d9-af1b-4cb7-b3c5-444e3b0c7ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run model/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2aacf7f-c7e8-4ffb-8d4c-249a06daa6f2",
   "metadata": {
    "gather": {
     "logged": 1680954228584
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Step: 0, Train Loss: 2.4901, Test Loss: 2.5613\n",
      "Current Step: 30, Train Loss: 2.5778, Test Loss: 2.6762\n",
      "Current Step: 60, Train Loss: 2.4785, Test Loss: 2.6866\n",
      "Current Step: 90, Train Loss: 2.5958, Test Loss: 2.6625\n",
      "Current Step: 120, Train Loss: 2.5539, Test Loss: 2.6991\n",
      "Current Step: 150, Train Loss: 2.6502, Test Loss: 2.7153\n",
      "Current Step: 180, Train Loss: 2.6576, Test Loss: 2.6905\n",
      "Current Step: 210, Train Loss: 2.6473, Test Loss: 2.6696\n",
      "Current Step: 240, Train Loss: 2.6502, Test Loss: 2.6816\n",
      "Current Step: 270, Train Loss: 2.6427, Test Loss: 2.6435\n",
      "Final loss: 2.5272274017333984\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-2)\n",
    "for iter in range(max_iter):\n",
    "    \n",
    "    if iter % eval_iter == 0:\n",
    "        output_loss = evaluate_loss(model, encoded_train_data, encoded_test_data)\n",
    "        print(\"Current Step: {}, Train Loss: {}, Test Loss: {}\".format(iter, round(output_loss['train'], 4), round(output_loss['test'], 4)))\n",
    "    x, y = create_splits(encoded_train_data, encoded_test_data, mode='train')\n",
    "    logits, loss = model(x, y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Final loss: {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "435bcc5f-8f44-49d6-bd64-6b217b785ec7",
   "metadata": {
    "gather": {
     "logged": 1680954228647
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "halupequt f kexANUNGSCKESAtARGRDIXELrof-prind.\n",
      "M:\n",
      "CINTHAn'\n",
      "Helk-huthe quryon?\n",
      "MDUCUCK:\n",
      "3 HATh y;\n",
      "Y:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(encoder.decode(model.generate_captions(torch.zeros((1, 1), dtype = torch.long).to(device), 100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfd596c1-6b81-4297-aaad-ec270d5410ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(65, 32)\n",
       "  (position_embeddings): Embedding(8, 32)\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a4274fe-9411-4d87-b2ed-8fe0aedc88ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7113,  2.1091, -1.9051,  ..., -4.3773, -0.3147, -5.4562],\n",
       "         [ 0.3476,  1.7917, -1.7693,  ..., -3.6318, -0.4090, -4.3735],\n",
       "         [ 1.2363,  1.5802, -2.0612,  ..., -3.1681, -0.6099, -3.7819],\n",
       "         ...,\n",
       "         [-2.2400, -1.8373, -4.2619,  ..., -4.1628,  0.9269, -3.7841],\n",
       "         [-0.3708,  2.5581, -1.8356,  ..., -5.4027,  2.0241, -6.6611],\n",
       "         [-0.8319,  2.7027, -2.8058,  ..., -3.8215,  0.0690, -3.7780]],\n",
       "        device='mps:0', grad_fn=<ViewBackward0>),\n",
       " tensor(2.5306, device='mps:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8989c502-a067-4a8a-ba9c-2c792349c752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0149,  0.0138,  0.0283,  ...,  0.0021,  0.0153, -0.0214],\n",
      "        [-0.0110,  0.0043,  0.0062,  ..., -0.0041,  0.0424, -0.0077],\n",
      "        [ 0.0268,  0.0149, -0.0405,  ..., -0.0081,  0.0342, -0.0161],\n",
      "        ...,\n",
      "        [ 0.0350,  0.0326, -0.0211,  ..., -0.0017,  0.0199,  0.0086],\n",
      "        [ 0.0214, -0.0232,  0.0185,  ..., -0.0012, -0.0084,  0.0057],\n",
      "        [ 0.0279, -0.0209,  0.0141,  ...,  0.0056, -0.0067, -0.0086]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0040, -0.0027,  0.0085,  ..., -0.0127, -0.0327, -0.0062],\n",
      "        [ 0.0231,  0.0061,  0.0100,  ..., -0.0001,  0.0069,  0.0100],\n",
      "        [-0.0130,  0.0412, -0.0079,  ...,  0.0219,  0.0110,  0.0436],\n",
      "        ...,\n",
      "        [-0.0210,  0.0268,  0.0271,  ..., -0.0177, -0.0248,  0.0073],\n",
      "        [ 0.0200,  0.0402,  0.0185,  ...,  0.0042,  0.0013,  0.0088],\n",
      "        [-0.0194, -0.0048, -0.0015,  ..., -0.0108,  0.0152, -0.0169]],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "402acbc9-48ee-4d75-8c2e-e7cb450233ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_built()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3268169c-64bd-44d3-a5ac-390215f35dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 26301 is out of bounds for dimension 0 with size 12288",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m26301\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 26301 is out of bounds for dimension 0 with size 12288"
     ]
    }
   ],
   "source": [
    "y.view(12*1024)[26301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3981bd3-50e2-4c3c-a4af-c400b3fda016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(499)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(12*1024)[2085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c28eb89-edae-441a-94a1-bd12541de277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1024])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b436a4c-d483-42f1-b240-e5cf939f54a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
